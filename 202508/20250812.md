# 🐳 Kubernetes 💙 MLOps

- 현재 많은 기업들이 MLOps 시스템 구축과 운영에 Kubernetes를 적극적으로 활용하고 있습니다. 그렇다면, 왜 이렇게 MLOps 환경에서 Kubernetes가 널리 사용되고, 핵심 인프라로 자리 잡게 되었을까요?


## 🤖 MLOps?
먼저 MLOps에 대해 간단히 알아보겠습니다
- ML과 DevOps의 통합 – MLOps는 머신러닝(ML) 워크플로를 DevOps 원칙과 결합하여 ML 모델의 개발, 배포, 운영을 효율적으로 관리하는 방법입니다.
- 자동화와 모니터링 – 데이터 파이프라인, 모델 학습, 배포, 지속적인 모니터링을 자동화하여 모델의 정확성, 신뢰성, 최신 상태를 유지합니다.
- 협업과 확장성 – 데이터 사이언티스트, ML 엔지니어, 운영팀 간의 협업을 촉진하고, 확장 가능하고 재현 가능한 ML 시스템을 구축합니다.

## Kubernetes?
다음은 kubernetes (k8s)에 대해 간단히 알아보겠습니다
- 쿠버네티스(Kubernetes)는 컨테이너화된 애플리케이션을 자동으로 배포, 확장, 관리하는 오픈소스 플랫폼입니다.
주요 특징은 다음과 같습니다:
  - 자동 배포와 확장 – 애플리케이션을 필요에 따라 자동으로 늘리거나 줄입니다.
  - 일관된 실행 환경 – 컨테이너를 사용해 개발·테스트·운영 환경을 동일하게 유지합니다.
  - 자가 치유(Self-healing) – 장애가 난 컨테이너를 자동으로 재시작하거나 교체해 서비스 가용성을 높입니다.

## MLOps에서 k8s활용
- 컨테이너 기반의 일관된 실행 환경과 자가 치유 기능을 제공하는 Kubernetes는 MLOps에서 요구되는 핵심적인 안정성과 재현성을 효과적으로 보장합니다.

1. 컨테이너화 및 환경 일관성 확보
- Kubernetes는 애플리케이션을 컨테이너로 패키징하고, 이를 클러스터 환경에서 일관되게 배포, 실행합니다. 이는 개발·테스트·운영 환경에서 모두 동일한 구성을 보장하므로, ML 워크플로우의 반복성과 신뢰성을 높여줍니다  

2. 확장성과 리소스 관리
- CPU/GPU 리소스를 필요에 따라 자동으로 확장하거나 축소할 수 있어, 트레이닝 및 추론 워크로드를 유연하게 처리할 수 있습니다. 이를 통해 자원 사용의 효율성과 비용 효율성이 향상됩니다. GPU 자원을 많이 소모하는 딥러닝 훈련 / 배포에서 k8s의 리소스 관리에 특히 유용하게 사용됩니다

3. 자동화된 배포 및 오케스트레이션
- Kubeflow Pipelines를 통해 데이터 준비, 모델 학습, 배포, 모니터링 등 MLOps 단계 전 과정을 자동화된 파이프라인으로 구축할 수 있습니다. 이 플랫폼은 Kubernetes 위에서 확장 가능하고, 재사용 가능한 모듈 기반 워크플로우를 제공합니다  ￼.
- Kubernetes 자체도 다양한 워크로드(예: 배치 작업, 서비스 등)의 스케줄링, 자동 확장, 롤링 업데이트 등을 지원해 CI/CD를 통한 ML 모델 배포를 촉진할 수 있습니다  

#### 참조 링크
[커피고래의 노트: Kubernetes와 MLOps](https://coffeewhale.com/kubernetes/ml/k8s/docker/machine-learning/2019/01/11/k8s-ml-01/)

[Kubeflow 공식문서](https://www.kubeflow.org/docs/started/introduction/)